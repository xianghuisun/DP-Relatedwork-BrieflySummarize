2022-01-02 07:34:16,030 - main - INFO - <module> - 50 : Using device cuda
2022-01-02 07:35:19,762 - main - INFO - <module> - 50 : Using device cuda
2022-01-02 07:35:50,469 - main - INFO - <module> - 50 : Using device cuda
2022-01-02 07:36:11,232 - main - INFO - <module> - 50 : Using device cuda
2022-01-02 07:36:11,826 - main - INFO - main - 190 : Tag scheme : 
2022-01-02 07:36:11,826 - main - INFO - main - 191 : Tag has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/label.json
2022-01-02 07:36:11,844 - main - INFO - main - 221 : bert_model_name_or_path:/home/xhsun/NLP/huggingfaceModels/English/bert-base-uncased
2022-01-02 07:36:11,844 - main - INFO - main - 221 : file_path:/home/xhsun/.conll/
2022-01-02 07:36:11,844 - main - INFO - main - 221 : save_dir:/home/xhsun/Desktop/NER_Parsing/train_models/baseline_models
2022-01-02 07:36:11,844 - main - INFO - main - 221 : ckpt:None
2022-01-02 07:36:11,844 - main - INFO - main - 221 : learning_rate:3e-05
2022-01-02 07:36:11,844 - main - INFO - main - 221 : weight_decay:1e-05
2022-01-02 07:36:11,844 - main - INFO - main - 221 : epochs:5
2022-01-02 07:36:11,844 - main - INFO - main - 221 : train_batch_size:64
2022-01-02 07:36:11,844 - main - INFO - main - 221 : dev_batch_size:64
2022-01-02 07:36:11,844 - main - INFO - main - 221 : max_grad_norm:1
2022-01-02 07:36:11,844 - main - INFO - main - 221 : warmup_proportion:0.1
2022-01-02 07:36:11,844 - main - INFO - main - 221 : max_len:128
2022-01-02 07:36:11,844 - main - INFO - main - 221 : seed:666
2022-01-02 07:36:11,844 - main - INFO - main - 221 : num_workers:1
2022-01-02 07:36:11,844 - main - INFO - train - 59 : n_tags : 1
2022-01-02 07:36:11,844 - main - INFO - train - 63 : Under an epoch, loss will be output every 44 step, and the model will be evaluated every 110 step
2022-01-02 07:36:14,986 - main - INFO - train - 71 : Using device : cuda
2022-01-02 07:40:10,016 - main - INFO - <module> - 50 : Using device cuda
2022-01-02 07:40:10,595 - main - INFO - main - 191 : Tag scheme : 
2022-01-02 07:40:10,595 - main - INFO - main - 192 : Tag has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/label.json
2022-01-02 07:40:10,610 - main - INFO - main - 222 : bert_model_name_or_path:/home/xhsun/NLP/huggingfaceModels/English/bert-base-uncased
2022-01-02 07:40:10,610 - main - INFO - main - 222 : file_path:/home/xhsun/.conll/
2022-01-02 07:40:10,610 - main - INFO - main - 222 : save_dir:/home/xhsun/Desktop/NER_Parsing/train_models/baseline_models
2022-01-02 07:40:10,610 - main - INFO - main - 222 : ckpt:None
2022-01-02 07:40:10,610 - main - INFO - main - 222 : learning_rate:3e-05
2022-01-02 07:40:10,610 - main - INFO - main - 222 : weight_decay:1e-05
2022-01-02 07:40:10,610 - main - INFO - main - 222 : epochs:5
2022-01-02 07:40:10,610 - main - INFO - main - 222 : train_batch_size:64
2022-01-02 07:40:10,610 - main - INFO - main - 222 : dev_batch_size:64
2022-01-02 07:40:10,610 - main - INFO - main - 222 : max_grad_norm:1
2022-01-02 07:40:10,610 - main - INFO - main - 222 : warmup_proportion:0.1
2022-01-02 07:40:10,610 - main - INFO - main - 222 : max_len:128
2022-01-02 07:40:10,610 - main - INFO - main - 222 : seed:666
2022-01-02 07:40:10,610 - main - INFO - main - 222 : num_workers:1
2022-01-02 07:40:10,610 - main - INFO - train - 60 : n_tags : 1
2022-01-02 07:40:10,610 - main - INFO - train - 64 : Under an epoch, loss will be output every 44 step, and the model will be evaluated every 110 step
2022-01-02 07:40:13,154 - main - INFO - train - 72 : Using device : cuda
2022-01-02 07:40:13,156 - main - INFO - train - 77 : num_train_steps : 1095, warmup_proportion : 0.1, warmup_steps : 109.5
2022-01-02 07:42:01,253 - main - INFO - <module> - 50 : Using device cuda
2022-01-02 07:42:01,814 - main - INFO - main - 191 : Tag scheme : 
2022-01-02 07:42:01,815 - main - INFO - main - 192 : Tag has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/label.json
2022-01-02 07:42:01,830 - main - INFO - main - 222 : bert_model_name_or_path:/home/xhsun/NLP/huggingfaceModels/English/bert-base-uncased
2022-01-02 07:42:01,830 - main - INFO - main - 222 : file_path:/home/xhsun/.conll/
2022-01-02 07:42:01,830 - main - INFO - main - 222 : save_dir:/home/xhsun/Desktop/NER_Parsing/train_models/baseline_models
2022-01-02 07:42:01,830 - main - INFO - main - 222 : ckpt:None
2022-01-02 07:42:01,830 - main - INFO - main - 222 : learning_rate:3e-05
2022-01-02 07:42:01,830 - main - INFO - main - 222 : weight_decay:1e-05
2022-01-02 07:42:01,830 - main - INFO - main - 222 : epochs:5
2022-01-02 07:42:01,830 - main - INFO - main - 222 : train_batch_size:64
2022-01-02 07:42:01,830 - main - INFO - main - 222 : dev_batch_size:64
2022-01-02 07:42:01,830 - main - INFO - main - 222 : max_grad_norm:1
2022-01-02 07:42:01,830 - main - INFO - main - 222 : warmup_proportion:0.1
2022-01-02 07:42:01,830 - main - INFO - main - 222 : max_len:128
2022-01-02 07:42:01,830 - main - INFO - main - 222 : seed:666
2022-01-02 07:42:01,830 - main - INFO - main - 222 : num_workers:1
2022-01-02 07:42:01,830 - main - INFO - train - 60 : n_tags : 1
2022-01-02 07:42:01,830 - main - INFO - train - 64 : Under an epoch, loss will be output every 44 step, and the model will be evaluated every 110 step
2022-01-02 07:42:04,245 - main - INFO - train - 72 : Using device : cuda
2022-01-02 07:42:04,246 - main - INFO - train - 77 : num_train_steps : 1095, warmup_proportion : 0.1, warmup_steps : 109.5
2022-01-02 07:46:47,890 - main - INFO - <module> - 50 : Using device cuda
2022-01-02 07:46:48,463 - main - INFO - main - 191 : Tag scheme : B-LOC B-ORG I-MISC I-ORG I-LOC I-PER B-PER B-MISC
2022-01-02 07:46:48,463 - main - INFO - main - 192 : Tag has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/label.json
2022-01-02 07:46:48,478 - main - INFO - main - 222 : bert_model_name_or_path:/home/xhsun/NLP/huggingfaceModels/English/bert-base-uncased
2022-01-02 07:46:48,478 - main - INFO - main - 222 : file_path:/home/xhsun/.conll/
2022-01-02 07:46:48,478 - main - INFO - main - 222 : save_dir:/home/xhsun/Desktop/NER_Parsing/train_models/baseline_models
2022-01-02 07:46:48,478 - main - INFO - main - 222 : ckpt:None
2022-01-02 07:46:48,478 - main - INFO - main - 222 : learning_rate:3e-05
2022-01-02 07:46:48,478 - main - INFO - main - 222 : weight_decay:1e-05
2022-01-02 07:46:48,478 - main - INFO - main - 222 : epochs:5
2022-01-02 07:46:48,478 - main - INFO - main - 222 : train_batch_size:64
2022-01-02 07:46:48,478 - main - INFO - main - 222 : dev_batch_size:64
2022-01-02 07:46:48,478 - main - INFO - main - 222 : max_grad_norm:1
2022-01-02 07:46:48,478 - main - INFO - main - 222 : warmup_proportion:0.1
2022-01-02 07:46:48,478 - main - INFO - main - 222 : max_len:128
2022-01-02 07:46:48,478 - main - INFO - main - 222 : seed:666
2022-01-02 07:46:48,478 - main - INFO - main - 222 : num_workers:1
2022-01-02 07:46:48,478 - main - INFO - train - 60 : n_tags : 9
2022-01-02 07:46:48,478 - main - INFO - train - 64 : Under an epoch, loss will be output every 44 step, and the model will be evaluated every 110 step
2022-01-02 07:46:50,947 - main - INFO - train - 72 : Using device : cuda
2022-01-02 07:46:50,948 - main - INFO - train - 77 : num_train_steps : 1095, warmup_proportion : 0.1, warmup_steps : 109.5
2022-01-02 07:48:14,225 - main - INFO - <module> - 50 : Using device cuda
2022-01-02 07:48:14,800 - main - INFO - main - 191 : Tag scheme : B-MISC I-PER I-MISC B-ORG B-LOC B-PER I-LOC I-ORG
2022-01-02 07:48:14,800 - main - INFO - main - 192 : Tag has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/label.json
2022-01-02 07:48:14,814 - main - INFO - main - 222 : bert_model_name_or_path:/home/xhsun/NLP/huggingfaceModels/English/bert-base-uncased
2022-01-02 07:48:14,814 - main - INFO - main - 222 : file_path:/home/xhsun/.conll/
2022-01-02 07:48:14,815 - main - INFO - main - 222 : save_dir:/home/xhsun/Desktop/NER_Parsing/train_models/baseline_models
2022-01-02 07:48:14,815 - main - INFO - main - 222 : ckpt:None
2022-01-02 07:48:14,815 - main - INFO - main - 222 : learning_rate:3e-05
2022-01-02 07:48:14,815 - main - INFO - main - 222 : weight_decay:1e-05
2022-01-02 07:48:14,815 - main - INFO - main - 222 : epochs:5
2022-01-02 07:48:14,815 - main - INFO - main - 222 : train_batch_size:64
2022-01-02 07:48:14,815 - main - INFO - main - 222 : dev_batch_size:64
2022-01-02 07:48:14,815 - main - INFO - main - 222 : max_grad_norm:1
2022-01-02 07:48:14,815 - main - INFO - main - 222 : warmup_proportion:0.1
2022-01-02 07:48:14,815 - main - INFO - main - 222 : max_len:128
2022-01-02 07:48:14,815 - main - INFO - main - 222 : seed:666
2022-01-02 07:48:14,815 - main - INFO - main - 222 : num_workers:1
2022-01-02 07:48:14,815 - main - INFO - train - 60 : n_tags : 9
2022-01-02 07:48:14,815 - main - INFO - train - 64 : Under an epoch, loss will be output every 44 step, and the model will be evaluated every 110 step
2022-01-02 07:48:17,321 - main - INFO - train - 72 : Using device : cuda
2022-01-02 07:48:17,323 - main - INFO - train - 77 : num_train_steps : 1095, warmup_proportion : 0.1, warmup_steps : 109.5
2022-01-02 07:48:38,449 - main - INFO - <module> - 50 : Using device cuda
2022-01-02 07:48:39,036 - main - INFO - main - 191 : Tag scheme : I-LOC B-ORG I-ORG B-MISC B-LOC B-PER I-PER I-MISC
2022-01-02 07:48:39,036 - main - INFO - main - 192 : Tag has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/label.json
2022-01-02 07:48:39,050 - main - INFO - main - 222 : bert_model_name_or_path:/home/xhsun/NLP/huggingfaceModels/English/bert-base-uncased
2022-01-02 07:48:39,050 - main - INFO - main - 222 : file_path:/home/xhsun/.conll/
2022-01-02 07:48:39,050 - main - INFO - main - 222 : save_dir:/home/xhsun/Desktop/NER_Parsing/train_models/baseline_models
2022-01-02 07:48:39,051 - main - INFO - main - 222 : ckpt:None
2022-01-02 07:48:39,051 - main - INFO - main - 222 : learning_rate:3e-05
2022-01-02 07:48:39,051 - main - INFO - main - 222 : weight_decay:1e-05
2022-01-02 07:48:39,051 - main - INFO - main - 222 : epochs:5
2022-01-02 07:48:39,051 - main - INFO - main - 222 : train_batch_size:64
2022-01-02 07:48:39,051 - main - INFO - main - 222 : dev_batch_size:64
2022-01-02 07:48:39,051 - main - INFO - main - 222 : max_grad_norm:1
2022-01-02 07:48:39,051 - main - INFO - main - 222 : warmup_proportion:0.1
2022-01-02 07:48:39,051 - main - INFO - main - 222 : max_len:128
2022-01-02 07:48:39,051 - main - INFO - main - 222 : seed:666
2022-01-02 07:48:39,051 - main - INFO - main - 222 : num_workers:1
2022-01-02 07:48:39,051 - main - INFO - train - 60 : n_tags : 9
2022-01-02 07:48:39,051 - main - INFO - train - 64 : Under an epoch, loss will be output every 44 step, and the model will be evaluated every 110 step
2022-01-02 07:48:41,591 - main - INFO - train - 72 : Using device : cuda
2022-01-02 07:48:41,593 - main - INFO - train - 77 : num_train_steps : 1095, warmup_proportion : 0.1, warmup_steps : 109.5
2022-01-02 07:51:27,745 - main - INFO - <module> - 50 : Using device cuda
2022-01-02 07:51:28,320 - main - INFO - main - 191 : Tag scheme : I-PER B-LOC B-ORG I-MISC I-ORG B-PER I-LOC B-MISC
2022-01-02 07:51:28,320 - main - INFO - main - 192 : Tag has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/label.json
2022-01-02 07:51:28,334 - main - INFO - main - 222 : bert_model_name_or_path:/home/xhsun/NLP/huggingfaceModels/English/bert-base-uncased
2022-01-02 07:51:28,334 - main - INFO - main - 222 : file_path:/home/xhsun/.conll/
2022-01-02 07:51:28,335 - main - INFO - main - 222 : save_dir:/home/xhsun/Desktop/NER_Parsing/train_models/baseline_models
2022-01-02 07:51:28,335 - main - INFO - main - 222 : ckpt:None
2022-01-02 07:51:28,335 - main - INFO - main - 222 : learning_rate:3e-05
2022-01-02 07:51:28,335 - main - INFO - main - 222 : weight_decay:1e-05
2022-01-02 07:51:28,335 - main - INFO - main - 222 : epochs:5
2022-01-02 07:51:28,335 - main - INFO - main - 222 : train_batch_size:64
2022-01-02 07:51:28,335 - main - INFO - main - 222 : dev_batch_size:64
2022-01-02 07:51:28,335 - main - INFO - main - 222 : max_grad_norm:1
2022-01-02 07:51:28,335 - main - INFO - main - 222 : warmup_proportion:0.1
2022-01-02 07:51:28,335 - main - INFO - main - 222 : max_len:128
2022-01-02 07:51:28,335 - main - INFO - main - 222 : seed:666
2022-01-02 07:51:28,335 - main - INFO - main - 222 : num_workers:1
2022-01-02 07:51:28,335 - main - INFO - train - 60 : n_tags : 9
2022-01-02 07:51:28,335 - main - INFO - train - 64 : Under an epoch, loss will be output every 44 step, and the model will be evaluated every 110 step
2022-01-02 07:51:30,804 - main - INFO - train - 72 : Using device : cuda
2022-01-02 07:51:30,806 - main - INFO - train - 77 : num_train_steps : 1095, warmup_proportion : 0.1, warmup_steps : 109.5
2022-01-02 07:54:48,432 - main - INFO - <module> - 50 : Using device cuda
2022-01-02 07:54:49,018 - main - INFO - main - 194 : Tag scheme : I-ORG B-ORG B-PER B-LOC I-LOC B-MISC I-MISC I-PER
2022-01-02 07:54:49,018 - main - INFO - main - 195 : Tag has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/label.json
2022-01-02 07:54:49,032 - main - INFO - main - 225 : bert_model_name_or_path:/home/xhsun/NLP/huggingfaceModels/English/bert-base-uncased
2022-01-02 07:54:49,033 - main - INFO - main - 225 : file_path:/home/xhsun/.conll/
2022-01-02 07:54:49,033 - main - INFO - main - 225 : save_dir:/home/xhsun/Desktop/NER_Parsing/train_models/baseline_models
2022-01-02 07:54:49,033 - main - INFO - main - 225 : ckpt:None
2022-01-02 07:54:49,033 - main - INFO - main - 225 : learning_rate:3e-05
2022-01-02 07:54:49,033 - main - INFO - main - 225 : weight_decay:1e-05
2022-01-02 07:54:49,033 - main - INFO - main - 225 : epochs:5
2022-01-02 07:54:49,033 - main - INFO - main - 225 : train_batch_size:64
2022-01-02 07:54:49,033 - main - INFO - main - 225 : dev_batch_size:64
2022-01-02 07:54:49,033 - main - INFO - main - 225 : max_grad_norm:1
2022-01-02 07:54:49,033 - main - INFO - main - 225 : warmup_proportion:0.1
2022-01-02 07:54:49,033 - main - INFO - main - 225 : max_len:128
2022-01-02 07:54:49,033 - main - INFO - main - 225 : seed:666
2022-01-02 07:54:49,033 - main - INFO - main - 225 : num_workers:1
2022-01-02 07:54:49,033 - main - INFO - train - 60 : n_tags : 9
2022-01-02 07:54:49,033 - main - INFO - train - 64 : Under an epoch, loss will be output every 44 step, and the model will be evaluated every 110 step
2022-01-02 07:54:51,512 - main - INFO - train - 72 : Using device : cuda
2022-01-02 07:54:51,513 - main - INFO - train - 77 : num_train_steps : 1095, warmup_proportion : 0.1, warmup_steps : 109.5
2022-01-02 07:57:50,165 - main - INFO - <module> - 50 : Using device cuda
2022-01-02 07:57:50,728 - main - INFO - main - 194 : Tag scheme : B-LOC B-MISC B-PER I-LOC I-PER I-ORG B-ORG I-MISC
2022-01-02 07:57:50,729 - main - INFO - main - 195 : Tag has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/label.json
2022-01-02 07:57:50,743 - main - INFO - main - 225 : bert_model_name_or_path:/home/xhsun/NLP/huggingfaceModels/English/bert-base-uncased
2022-01-02 07:57:50,743 - main - INFO - main - 225 : file_path:/home/xhsun/.conll/
2022-01-02 07:57:50,743 - main - INFO - main - 225 : save_dir:/home/xhsun/Desktop/NER_Parsing/train_models/baseline_models
2022-01-02 07:57:50,744 - main - INFO - main - 225 : ckpt:None
2022-01-02 07:57:50,744 - main - INFO - main - 225 : learning_rate:3e-05
2022-01-02 07:57:50,744 - main - INFO - main - 225 : weight_decay:1e-05
2022-01-02 07:57:50,744 - main - INFO - main - 225 : epochs:5
2022-01-02 07:57:50,744 - main - INFO - main - 225 : train_batch_size:64
2022-01-02 07:57:50,744 - main - INFO - main - 225 : dev_batch_size:64
2022-01-02 07:57:50,744 - main - INFO - main - 225 : max_grad_norm:1
2022-01-02 07:57:50,744 - main - INFO - main - 225 : warmup_proportion:0.1
2022-01-02 07:57:50,744 - main - INFO - main - 225 : max_len:128
2022-01-02 07:57:50,744 - main - INFO - main - 225 : seed:666
2022-01-02 07:57:50,744 - main - INFO - main - 225 : num_workers:1
2022-01-02 07:57:50,744 - main - INFO - train - 60 : n_tags : 9
2022-01-02 07:57:50,744 - main - INFO - train - 64 : Under an epoch, loss will be output every 44 step, and the model will be evaluated every 110 step
2022-01-02 07:57:53,202 - main - INFO - train - 72 : Using device : cuda
2022-01-02 07:57:53,204 - main - INFO - train - 77 : num_train_steps : 1095, warmup_proportion : 0.1, warmup_steps : 109
2022-01-02 07:59:34,085 - main - INFO - <module> - 50 : Using device cuda
2022-01-02 07:59:34,648 - main - INFO - main - 194 : Tag scheme : B-PER B-ORG B-LOC B-MISC I-PER I-MISC I-ORG I-LOC
2022-01-02 07:59:34,649 - main - INFO - main - 195 : Tag has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/label.json
2022-01-02 07:59:34,663 - main - INFO - main - 225 : bert_model_name_or_path:/home/xhsun/NLP/huggingfaceModels/English/bert-base-uncased
2022-01-02 07:59:34,663 - main - INFO - main - 225 : file_path:/home/xhsun/.conll/
2022-01-02 07:59:34,663 - main - INFO - main - 225 : save_dir:/home/xhsun/Desktop/NER_Parsing/train_models/baseline_models
2022-01-02 07:59:34,663 - main - INFO - main - 225 : ckpt:None
2022-01-02 07:59:34,663 - main - INFO - main - 225 : learning_rate:3e-05
2022-01-02 07:59:34,663 - main - INFO - main - 225 : weight_decay:1e-05
2022-01-02 07:59:34,663 - main - INFO - main - 225 : epochs:5
2022-01-02 07:59:34,663 - main - INFO - main - 225 : train_batch_size:64
2022-01-02 07:59:34,663 - main - INFO - main - 225 : dev_batch_size:64
2022-01-02 07:59:34,663 - main - INFO - main - 225 : max_grad_norm:1
2022-01-02 07:59:34,663 - main - INFO - main - 225 : warmup_proportion:0.1
2022-01-02 07:59:34,663 - main - INFO - main - 225 : max_len:128
2022-01-02 07:59:34,663 - main - INFO - main - 225 : seed:666
2022-01-02 07:59:34,663 - main - INFO - main - 225 : num_workers:1
2022-01-02 07:59:34,664 - main - INFO - train - 60 : n_tags : 9
2022-01-02 07:59:34,664 - main - INFO - train - 64 : Under an epoch, loss will be output every 44 step, and the model will be evaluated every 110 step
2022-01-02 07:59:37,098 - main - INFO - train - 72 : Using device : cuda
2022-01-02 07:59:37,100 - main - INFO - train - 77 : num_train_steps : 1095, warmup_proportion : 0.1, warmup_steps : 109
2022-01-02 08:02:18,292 - main - INFO - <module> - 50 : Using device cuda
2022-01-02 08:02:18,871 - main - INFO - main - 194 : Tag scheme : I-LOC I-ORG B-MISC I-MISC I-PER B-ORG B-PER B-LOC
2022-01-02 08:02:18,871 - main - INFO - main - 195 : Tag has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/label.json
2022-01-02 08:02:18,886 - main - INFO - main - 225 : bert_model_name_or_path:/home/xhsun/NLP/huggingfaceModels/English/bert-base-uncased
2022-01-02 08:02:18,886 - main - INFO - main - 225 : file_path:/home/xhsun/.conll/
2022-01-02 08:02:18,886 - main - INFO - main - 225 : save_dir:/home/xhsun/Desktop/NER_Parsing/train_models/baseline_models
2022-01-02 08:02:18,886 - main - INFO - main - 225 : ckpt:None
2022-01-02 08:02:18,886 - main - INFO - main - 225 : learning_rate:3e-05
2022-01-02 08:02:18,886 - main - INFO - main - 225 : weight_decay:1e-05
2022-01-02 08:02:18,886 - main - INFO - main - 225 : epochs:5
2022-01-02 08:02:18,886 - main - INFO - main - 225 : train_batch_size:64
2022-01-02 08:02:18,886 - main - INFO - main - 225 : dev_batch_size:64
2022-01-02 08:02:18,886 - main - INFO - main - 225 : max_grad_norm:1
2022-01-02 08:02:18,886 - main - INFO - main - 225 : warmup_proportion:0.1
2022-01-02 08:02:18,886 - main - INFO - main - 225 : max_len:128
2022-01-02 08:02:18,886 - main - INFO - main - 225 : seed:666
2022-01-02 08:02:18,886 - main - INFO - main - 225 : num_workers:1
2022-01-02 08:02:18,886 - main - INFO - train - 60 : n_tags : 9
2022-01-02 08:02:18,886 - main - INFO - train - 64 : Under an epoch, loss will be output every 44 step, and the model will be evaluated every 110 step
2022-01-02 08:02:21,402 - main - INFO - train - 72 : Using device : cuda
2022-01-02 08:02:21,403 - main - INFO - train - 77 : num_train_steps : 1095, warmup_proportion : 0.1, warmup_steps : 109
2022-01-02 08:03:17,941 - main - INFO - <module> - 50 : Using device cuda
2022-01-02 08:03:18,543 - main - INFO - main - 194 : Tag scheme : I-ORG I-MISC I-PER B-MISC B-LOC B-PER B-ORG I-LOC
2022-01-02 08:03:18,543 - main - INFO - main - 195 : Tag has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/label.json
2022-01-02 08:03:18,558 - main - INFO - main - 225 : bert_model_name_or_path:/home/xhsun/NLP/huggingfaceModels/English/bert-base-uncased
2022-01-02 08:03:18,558 - main - INFO - main - 225 : file_path:/home/xhsun/.conll/
2022-01-02 08:03:18,558 - main - INFO - main - 225 : save_dir:/home/xhsun/Desktop/NER_Parsing/train_models/baseline_models
2022-01-02 08:03:18,558 - main - INFO - main - 225 : ckpt:None
2022-01-02 08:03:18,558 - main - INFO - main - 225 : learning_rate:3e-05
2022-01-02 08:03:18,558 - main - INFO - main - 225 : weight_decay:1e-05
2022-01-02 08:03:18,558 - main - INFO - main - 225 : epochs:5
2022-01-02 08:03:18,558 - main - INFO - main - 225 : train_batch_size:64
2022-01-02 08:03:18,558 - main - INFO - main - 225 : dev_batch_size:64
2022-01-02 08:03:18,558 - main - INFO - main - 225 : max_grad_norm:1
2022-01-02 08:03:18,558 - main - INFO - main - 225 : warmup_proportion:0.1
2022-01-02 08:03:18,558 - main - INFO - main - 225 : max_len:128
2022-01-02 08:03:18,558 - main - INFO - main - 225 : seed:666
2022-01-02 08:03:18,558 - main - INFO - main - 225 : num_workers:1
2022-01-02 08:03:18,558 - main - INFO - train - 60 : n_tags : 9
2022-01-02 08:03:18,558 - main - INFO - train - 64 : Under an epoch, loss will be output every 44 step, and the model will be evaluated every 110 step
2022-01-02 08:03:21,091 - main - INFO - train - 72 : Using device : cuda
2022-01-02 08:03:21,092 - main - INFO - train - 77 : num_train_steps : 1095, warmup_proportion : 0.1, warmup_steps : 109
2022-01-02 08:04:12,718 - main - INFO - <module> - 50 : Using device cuda
2022-01-02 08:04:13,303 - main - INFO - main - 195 : Tag scheme : I-MISC B-ORG B-PER I-ORG I-PER B-MISC I-LOC B-LOC
2022-01-02 08:04:13,303 - main - INFO - main - 196 : Tag has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/label.json
2022-01-02 08:04:13,317 - main - INFO - main - 226 : bert_model_name_or_path:/home/xhsun/NLP/huggingfaceModels/English/bert-base-uncased
2022-01-02 08:04:13,318 - main - INFO - main - 226 : file_path:/home/xhsun/.conll/
2022-01-02 08:04:13,318 - main - INFO - main - 226 : save_dir:/home/xhsun/Desktop/NER_Parsing/train_models/baseline_models
2022-01-02 08:04:13,318 - main - INFO - main - 226 : ckpt:None
2022-01-02 08:04:13,318 - main - INFO - main - 226 : learning_rate:3e-05
2022-01-02 08:04:13,318 - main - INFO - main - 226 : weight_decay:1e-05
2022-01-02 08:04:13,318 - main - INFO - main - 226 : epochs:5
2022-01-02 08:04:13,318 - main - INFO - main - 226 : train_batch_size:64
2022-01-02 08:04:13,318 - main - INFO - main - 226 : dev_batch_size:64
2022-01-02 08:04:13,318 - main - INFO - main - 226 : max_grad_norm:1
2022-01-02 08:04:13,318 - main - INFO - main - 226 : warmup_proportion:0.1
2022-01-02 08:04:13,318 - main - INFO - main - 226 : max_len:128
2022-01-02 08:04:13,318 - main - INFO - main - 226 : seed:666
2022-01-02 08:04:13,318 - main - INFO - main - 226 : num_workers:1
2022-01-02 08:04:13,318 - main - INFO - train - 60 : n_tags : 9
2022-01-02 08:04:13,318 - main - INFO - train - 64 : Under an epoch, loss will be output every 44 step, and the model will be evaluated every 110 step
2022-01-02 08:04:15,846 - main - INFO - train - 72 : Using device : cuda
2022-01-02 08:04:15,847 - main - INFO - train - 77 : num_train_steps : 1095, warmup_proportion : 0.1, warmup_steps : 109
2022-01-02 08:05:44,485 - main - INFO - <module> - 50 : Using device cuda
2022-01-02 08:05:45,060 - main - INFO - main - 195 : Tag scheme : B-LOC I-PER B-MISC I-ORG B-PER B-ORG I-MISC I-LOC
2022-01-02 08:05:45,060 - main - INFO - main - 196 : Tag has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/label.json
2022-01-02 08:05:45,075 - main - INFO - main - 226 : bert_model_name_or_path:/home/xhsun/NLP/huggingfaceModels/English/bert-base-uncased
2022-01-02 08:05:45,075 - main - INFO - main - 226 : file_path:/home/xhsun/.conll/
2022-01-02 08:05:45,075 - main - INFO - main - 226 : save_dir:/home/xhsun/Desktop/NER_Parsing/train_models/baseline_models
2022-01-02 08:05:45,075 - main - INFO - main - 226 : ckpt:None
2022-01-02 08:05:45,075 - main - INFO - main - 226 : learning_rate:3e-05
2022-01-02 08:05:45,075 - main - INFO - main - 226 : weight_decay:1e-05
2022-01-02 08:05:45,075 - main - INFO - main - 226 : epochs:5
2022-01-02 08:05:45,075 - main - INFO - main - 226 : train_batch_size:64
2022-01-02 08:05:45,075 - main - INFO - main - 226 : dev_batch_size:64
2022-01-02 08:05:45,075 - main - INFO - main - 226 : max_grad_norm:1
2022-01-02 08:05:45,075 - main - INFO - main - 226 : warmup_proportion:0.1
2022-01-02 08:05:45,075 - main - INFO - main - 226 : max_len:196
2022-01-02 08:05:45,075 - main - INFO - main - 226 : seed:666
2022-01-02 08:05:45,075 - main - INFO - main - 226 : num_workers:1
2022-01-02 08:05:45,075 - main - INFO - train - 60 : n_tags : 9
2022-01-02 08:05:45,076 - main - INFO - train - 64 : Under an epoch, loss will be output every 44 step, and the model will be evaluated every 110 step
2022-01-02 08:05:47,544 - main - INFO - train - 72 : Using device : cuda
2022-01-02 08:05:47,546 - main - INFO - train - 77 : num_train_steps : 1095, warmup_proportion : 0.1, warmup_steps : 109
2022-01-02 08:05:58,271 - main.utils - INFO - compute_f1 - 128 :               precision    recall  f1-score   support

         LOC     0.0415    0.1541    0.0653      1837
        MISC     0.0160    0.1952    0.0296       922
         ORG     0.0068    0.0194    0.0101      1341
         PER     0.0074    0.0521    0.0129      1842

   micro avg     0.0168    0.0985    0.0287      5942
   macro avg     0.0179    0.1052    0.0295      5942
weighted avg     0.0191    0.0985    0.0311      5942

2022-01-02 08:05:58,271 - main.utils - INFO - compute_f1 - 129 : F1 : 0.028671551449506213, accuracy : 0.02951382043294823, precision : 0.016779004732539796, recall : 0.0984516997643891
2022-01-02 08:05:58,271 - main - INFO - train - 88 : Previous f1 score is -1 and current f1 score is 0.028671551449506213
2022-01-02 08:06:09,244 - main.utils - INFO - compute_f1 - 128 :               precision    recall  f1-score   support

         LOC     0.0415    0.1541    0.0653      1837
        MISC     0.0160    0.1952    0.0296       922
         ORG     0.0068    0.0194    0.0101      1341
         PER     0.0074    0.0521    0.0129      1842

   micro avg     0.0168    0.0985    0.0287      5942
   macro avg     0.0179    0.1052    0.0295      5942
weighted avg     0.0191    0.0985    0.0311      5942

2022-01-02 08:06:09,244 - main.utils - INFO - compute_f1 - 129 : F1 : 0.028671551449506213, accuracy : 0.02951382043294823, precision : 0.016779004732539796, recall : 0.0984516997643891
2022-01-02 08:07:32,741 - main - INFO - <module> - 51 : Using device cuda
2022-01-02 08:07:33,319 - main - INFO - main - 197 : Tag scheme : I-PER I-ORG I-MISC B-MISC B-LOC B-ORG I-LOC B-PER
2022-01-02 08:07:33,320 - main - INFO - main - 198 : Tag has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/label.json
2022-01-02 08:07:33,334 - main - INFO - main - 228 : bert_model_name_or_path:/home/xhsun/NLP/huggingfaceModels/English/bert-base-uncased
2022-01-02 08:07:33,334 - main - INFO - main - 228 : file_path:/home/xhsun/.conll/
2022-01-02 08:07:33,334 - main - INFO - main - 228 : save_dir:/home/xhsun/Desktop/NER_Parsing/train_models/baseline_models
2022-01-02 08:07:33,334 - main - INFO - main - 228 : ckpt:None
2022-01-02 08:07:33,334 - main - INFO - main - 228 : learning_rate:3e-05
2022-01-02 08:07:33,334 - main - INFO - main - 228 : weight_decay:1e-05
2022-01-02 08:07:33,335 - main - INFO - main - 228 : epochs:5
2022-01-02 08:07:33,335 - main - INFO - main - 228 : train_batch_size:64
2022-01-02 08:07:33,335 - main - INFO - main - 228 : dev_batch_size:64
2022-01-02 08:07:33,335 - main - INFO - main - 228 : max_grad_norm:1
2022-01-02 08:07:33,335 - main - INFO - main - 228 : warmup_proportion:0.1
2022-01-02 08:07:33,335 - main - INFO - main - 228 : max_len:196
2022-01-02 08:07:33,335 - main - INFO - main - 228 : patience:196
2022-01-02 08:07:33,335 - main - INFO - main - 228 : seed:666
2022-01-02 08:07:33,335 - main - INFO - main - 228 : num_workers:1
2022-01-02 08:07:33,335 - main - INFO - train - 61 : n_tags : 9
2022-01-02 08:07:33,335 - main - INFO - train - 65 : Under an epoch, loss will be output every 44 step, and the model will be evaluated every 110 step
2022-01-02 08:07:35,830 - main - INFO - train - 73 : Using device : cuda
2022-01-02 08:07:35,831 - main - INFO - train - 78 : num_train_steps : 1095, warmup_proportion : 0.1, warmup_steps : 109
2022-01-02 08:07:46,749 - main.utils - INFO - compute_f1 - 128 :               precision    recall  f1-score   support

         LOC     0.0415    0.1541    0.0653      1837
        MISC     0.0160    0.1952    0.0296       922
         ORG     0.0068    0.0194    0.0101      1341
         PER     0.0074    0.0521    0.0129      1842

   micro avg     0.0168    0.0985    0.0287      5942
   macro avg     0.0179    0.1052    0.0295      5942
weighted avg     0.0191    0.0985    0.0311      5942

2022-01-02 08:07:46,749 - main.utils - INFO - compute_f1 - 129 : F1 : 0.028671551449506213, accuracy : 0.02951382043294823, precision : 0.016779004732539796, recall : 0.0984516997643891
2022-01-02 08:07:46,749 - main - INFO - train - 89 : Previous f1 score is -1 and current f1 score is 0.028671551449506213
2022-01-02 08:07:47,124 - main - INFO - train - 111 : Epoch : 0, global_step : 1/1095, loss_value : 0.0530390739440918 
2022-01-02 08:07:57,719 - main.utils - INFO - compute_f1 - 128 :               precision    recall  f1-score   support

         LOC     0.0415    0.1541    0.0653      1837
        MISC     0.0160    0.1952    0.0296       922
         ORG     0.0068    0.0194    0.0101      1341
         PER     0.0074    0.0521    0.0129      1842

   micro avg     0.0168    0.0985    0.0287      5942
   macro avg     0.0179    0.1052    0.0295      5942
weighted avg     0.0191    0.0985    0.0311      5942

2022-01-02 08:07:57,719 - main.utils - INFO - compute_f1 - 129 : F1 : 0.028671551449506213, accuracy : 0.02951382043294823, precision : 0.016779004732539796, recall : 0.0984516997643891
2022-01-02 08:07:57,719 - main - INFO - train - 129 : Left patience is 195
2022-01-02 08:08:12,070 - main - INFO - train - 111 : Epoch : 0, global_step : 45/1095, loss_value : 1.6937524364753203 
2022-01-02 08:08:26,640 - main - INFO - train - 111 : Epoch : 0, global_step : 89/1095, loss_value : 0.7228176891803741 
2022-01-02 08:08:44,376 - main.utils - INFO - compute_f1 - 128 :               precision    recall  f1-score   support

         LOC     0.5569    0.6745    0.6100      1837
        MISC     0.6613    0.0445    0.0833       922
         ORG     0.3326    0.5757    0.4216      1341
         PER     0.9150    0.9001    0.9075      1842

   micro avg     0.5779    0.6244    0.6002      5942
   macro avg     0.6164    0.5487    0.5056      5942
weighted avg     0.6335    0.6244    0.5780      5942

2022-01-02 08:08:44,377 - main.utils - INFO - compute_f1 - 129 : F1 : 0.6002265005662515, accuracy : 0.9352746342809826, precision : 0.5778816199376947, recall : 0.6243688993604847
2022-01-02 08:08:44,726 - main - INFO - train - 124 : Previous f1 score is 0.028671551449506213 and current f1 score is 0.6002265005662515, best model has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/pytorch_model.bin
2022-01-02 08:08:51,912 - main - INFO - train - 111 : Epoch : 0, global_step : 133/1095, loss_value : 0.3180774458768693 
2022-01-02 08:09:06,278 - main - INFO - train - 111 : Epoch : 0, global_step : 177/1095, loss_value : 0.24159149842506106 
2022-01-02 08:09:20,925 - main - INFO - train - 111 : Epoch : 1, global_step : 221/1095, loss_value : 0.0027001112360845914 
2022-01-02 08:09:31,556 - main.utils - INFO - compute_f1 - 128 :               precision    recall  f1-score   support

         LOC     0.8323    0.8835    0.8571      1837
        MISC     0.7603    0.6226    0.6846       922
         ORG     0.7336    0.8770    0.7989      1341
         PER     0.9500    0.9381    0.9440      1842

   micro avg     0.8325    0.8585    0.8453      5942
   macro avg     0.8190    0.8303    0.8212      5942
weighted avg     0.8353    0.8585    0.8441      5942

2022-01-02 08:09:31,557 - main.utils - INFO - compute_f1 - 129 : F1 : 0.8453061562681249, accuracy : 0.9748629785891724, precision : 0.8325444752733802, recall : 0.8584651632446988
2022-01-02 08:09:32,037 - main - INFO - train - 124 : Previous f1 score is 0.6002265005662515 and current f1 score is 0.8453061562681249, best model has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/pytorch_model.bin
2022-01-02 08:09:46,823 - main - INFO - train - 111 : Epoch : 1, global_step : 265/1095, loss_value : 0.1490514410067011 
2022-01-02 08:10:01,496 - main - INFO - train - 111 : Epoch : 1, global_step : 309/1095, loss_value : 0.10911309109492735 
2022-01-02 08:10:19,724 - main.utils - INFO - compute_f1 - 128 :               precision    recall  f1-score   support

         LOC     0.9149    0.9428    0.9287      1837
        MISC     0.6990    0.7809    0.7377       922
         ORG     0.8549    0.8523    0.8536      1341
         PER     0.9676    0.9712    0.9694      1842

   micro avg     0.8813    0.9061    0.8935      5942
   macro avg     0.8591    0.8868    0.8723      5942
weighted avg     0.8842    0.9061    0.8947      5942

2022-01-02 08:10:19,724 - main.utils - INFO - compute_f1 - 129 : F1 : 0.8935358061571655, accuracy : 0.982985686684279, precision : 0.881322638729743, recall : 0.9060922248401212
2022-01-02 08:10:20,184 - main - INFO - train - 124 : Previous f1 score is 0.8453061562681249 and current f1 score is 0.8935358061571655, best model has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/pytorch_model.bin
2022-01-02 08:10:27,608 - main - INFO - train - 111 : Epoch : 1, global_step : 353/1095, loss_value : 0.07996369548014957 
2022-01-02 08:10:42,641 - main - INFO - train - 111 : Epoch : 1, global_step : 397/1095, loss_value : 0.0964251168241555 
2022-01-02 08:10:57,178 - main - INFO - train - 111 : Epoch : 2, global_step : 441/1095, loss_value : 0.001791680570353161 
2022-01-02 08:11:07,703 - main.utils - INFO - compute_f1 - 128 :               precision    recall  f1-score   support

         LOC     0.9444    0.9532    0.9488      1837
        MISC     0.8350    0.8286    0.8318       922
         ORG     0.8842    0.9053    0.8946      1341
         PER     0.9633    0.9691    0.9662      1842

   micro avg     0.9198    0.9280    0.9239      5942
   macro avg     0.9067    0.9140    0.9103      5942
weighted avg     0.9197    0.9280    0.9238      5942

2022-01-02 08:11:07,703 - main.utils - INFO - compute_f1 - 129 : F1 : 0.923850213621513, accuracy : 0.9869681794881905, precision : 0.91976647206005, recall : 0.9279703803433188
2022-01-02 08:11:08,155 - main - INFO - train - 124 : Previous f1 score is 0.8935358061571655 and current f1 score is 0.923850213621513, best model has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/pytorch_model.bin
2022-01-02 08:11:22,859 - main - INFO - train - 111 : Epoch : 2, global_step : 485/1095, loss_value : 0.07032250840513204 
2022-01-02 08:11:37,648 - main - INFO - train - 111 : Epoch : 2, global_step : 529/1095, loss_value : 0.051038085906343025 
2022-01-02 08:11:55,664 - main.utils - INFO - compute_f1 - 128 :               precision    recall  f1-score   support

         LOC     0.9503    0.9575    0.9539      1837
        MISC     0.8362    0.8416    0.8389       922
         ORG     0.8411    0.9239    0.8806      1341
         PER     0.9675    0.9522    0.9598      1842

   micro avg     0.9115    0.9303    0.9208      5942
   macro avg     0.8988    0.9188    0.9083      5942
weighted avg     0.9133    0.9303    0.9213      5942

2022-01-02 08:11:55,664 - main.utils - INFO - compute_f1 - 129 : F1 : 0.9207962022153744, accuracy : 0.9871456172863846, precision : 0.9114591920857379, recall : 0.9303264893975093
2022-01-02 08:11:55,664 - main - INFO - train - 129 : Left patience is 194
2022-01-02 08:12:03,026 - main - INFO - train - 111 : Epoch : 2, global_step : 573/1095, loss_value : 0.04437919538891451 
2022-01-02 08:12:17,824 - main - INFO - train - 111 : Epoch : 2, global_step : 617/1095, loss_value : 0.05066930358721451 
2022-01-02 08:12:32,567 - main - INFO - train - 111 : Epoch : 3, global_step : 661/1095, loss_value : 0.0009802184490994973 
2022-01-02 08:12:43,177 - main.utils - INFO - compute_f1 - 128 :               precision    recall  f1-score   support

         LOC     0.9639    0.9461    0.9549      1837
        MISC     0.8439    0.8623    0.8530       922
         ORG     0.8894    0.9172    0.9031      1341
         PER     0.9615    0.9767    0.9690      1842

   micro avg     0.9272    0.9360    0.9316      5942
   macro avg     0.9147    0.9256    0.9200      5942
weighted avg     0.9277    0.9360    0.9318      5942

2022-01-02 08:12:43,177 - main.utils - INFO - compute_f1 - 129 : F1 : 0.9315802696591575, accuracy : 0.9889397105792358, precision : 0.9271545257542924, recall : 0.9360484685291148
2022-01-02 08:12:43,664 - main - INFO - train - 124 : Previous f1 score is 0.923850213621513 and current f1 score is 0.9315802696591575, best model has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/pytorch_model.bin
2022-01-02 08:12:58,301 - main - INFO - train - 111 : Epoch : 3, global_step : 705/1095, loss_value : 0.038409733038861305 
2022-01-02 08:13:12,995 - main - INFO - train - 111 : Epoch : 3, global_step : 749/1095, loss_value : 0.02758340765616264 
2022-01-02 08:13:30,924 - main.utils - INFO - compute_f1 - 128 :               precision    recall  f1-score   support

         LOC     0.9698    0.9614    0.9656      1837
        MISC     0.8335    0.8905    0.8610       922
         ORG     0.8983    0.9284    0.9131      1341
         PER     0.9713    0.9750    0.9732      1842

   micro avg     0.9316    0.9472    0.9393      5942
   macro avg     0.9182    0.9388    0.9282      5942
weighted avg     0.9330    0.9472    0.9399      5942

2022-01-02 08:13:30,924 - main.utils - INFO - compute_f1 - 129 : F1 : 0.9393307185179004, accuracy : 0.9897874689483853, precision : 0.9316338354577057, recall : 0.9471558397845843
2022-01-02 08:13:31,366 - main - INFO - train - 124 : Previous f1 score is 0.9315802696591575 and current f1 score is 0.9393307185179004, best model has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/pytorch_model.bin
2022-01-02 08:13:38,708 - main - INFO - train - 111 : Epoch : 3, global_step : 793/1095, loss_value : 0.02572816412694837 
2022-01-02 08:13:53,440 - main - INFO - train - 111 : Epoch : 3, global_step : 837/1095, loss_value : 0.034556664679919115 
2022-01-02 08:14:08,100 - main - INFO - train - 111 : Epoch : 4, global_step : 881/1095, loss_value : 0.0008679727431048046 
2022-01-02 08:14:18,618 - main.utils - INFO - compute_f1 - 128 :               precision    recall  f1-score   support

         LOC     0.9689    0.9510    0.9599      1837
        MISC     0.8494    0.8807    0.8647       922
         ORG     0.8915    0.9314    0.9110      1341
         PER     0.9683    0.9783    0.9733      1842

   micro avg     0.9317    0.9441    0.9379      5942
   macro avg     0.9195    0.9353    0.9272      5942
weighted avg     0.9327    0.9441    0.9382      5942

2022-01-02 08:14:18,618 - main.utils - INFO - compute_f1 - 129 : F1 : 0.9378918331522194, accuracy : 0.9899057608138481, precision : 0.931738913801694, recall : 0.9441265567149109
2022-01-02 08:14:18,626 - main - INFO - train - 129 : Left patience is 193
2022-01-02 08:14:33,392 - main - INFO - train - 111 : Epoch : 4, global_step : 925/1095, loss_value : 0.02546175354985859 
2022-01-02 08:14:48,267 - main - INFO - train - 111 : Epoch : 4, global_step : 969/1095, loss_value : 0.018819189783905378 
2022-01-02 08:15:06,541 - main.utils - INFO - compute_f1 - 128 :               precision    recall  f1-score   support

         LOC     0.9637    0.9673    0.9655      1837
        MISC     0.8501    0.8915    0.8703       922
         ORG     0.9146    0.9262    0.9203      1341
         PER     0.9740    0.9750    0.9745      1842

   micro avg     0.9375    0.9487    0.9430      5942
   macro avg     0.9256    0.9400    0.9327      5942
weighted avg     0.9382    0.9487    0.9433      5942

2022-01-02 08:15:06,541 - main.utils - INFO - compute_f1 - 129 : F1 : 0.9430363864491844, accuracy : 0.9903592129647885, precision : 0.9374688175619491, recall : 0.9486704813194211
2022-01-02 08:15:07,038 - main - INFO - train - 124 : Previous f1 score is 0.9393307185179004 and current f1 score is 0.9430363864491844, best model has been saved in /home/xhsun/Desktop/NER_Parsing/train_models/baseline_models/pytorch_model.bin
2022-01-02 08:15:14,497 - main - INFO - train - 111 : Epoch : 4, global_step : 1013/1095, loss_value : 0.020008738884247246 
2022-01-02 08:15:29,318 - main - INFO - train - 111 : Epoch : 4, global_step : 1057/1095, loss_value : 0.02844093498424627 
