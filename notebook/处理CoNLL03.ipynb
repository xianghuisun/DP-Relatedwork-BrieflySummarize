{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed9aa369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,json\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3030134",
   "metadata": {},
   "source": [
    "# CoNLL03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1edc00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folder='/home/xhsun/NLP/NER/NerData/en_conll03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73ec4ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing_sentence(sentence_list):\n",
    "    sentence=' '.join(sentence_list)\n",
    "    doc=nlp(sentence)\n",
    "    result=[]\n",
    "    for token in doc:\n",
    "        word=token.text\n",
    "        deprel=token.dep_.lower()\n",
    "        head=token.head.text\n",
    "        pos_tag=token.pos_\n",
    "        try:\n",
    "            head_id=sentence_list.index(str(head))\n",
    "            #容易出现parsing错误的情况\n",
    "        except:\n",
    "            return None\n",
    "        if deprel=='root':\n",
    "            head_id=0\n",
    "        else:\n",
    "            head_id+=1\n",
    "        result.append([word,pos_tag,head_id,deprel])\n",
    "    return result\n",
    "\n",
    "def process_data(path_folder,write_path):\n",
    "    files_path=os.listdir(path_folder)\n",
    "    print(files_path)\n",
    "    for file_name in files_path:\n",
    "        with open(os.path.join(path_folder,file_name)) as f:\n",
    "            lines=f.readlines()\n",
    "        sentences_and_entlabels=[([],[])]\n",
    "        for line in lines:\n",
    "            if line.strip() in ['',' ']:\n",
    "                sentences_and_entlabels.append(([],[]))\n",
    "            else:\n",
    "                line_split=line.strip().split()\n",
    "                assert len(line_split)==2\n",
    "                word,entity_label=line_split\n",
    "                sentences_and_entlabels[-1][0].append(word)\n",
    "                sentences_and_entlabels[-1][1].append(entity_label)\n",
    "                \n",
    "        if sentences_and_entlabels[-1]==([],[]):\n",
    "            del sentences_and_entlabels[-1]\n",
    "            \n",
    "        with open(os.path.join(write_path,file_name+\".conllx\"),'w') as f:\n",
    "            parsing_error_count=0\n",
    "            for example in tqdm(sentences_and_entlabels):\n",
    "                sentences,entlabels=example\n",
    "                assert len(sentences)==len(entlabels)\n",
    "                \n",
    "                parsing_result=parsing_sentence(sentence_list=sentences)\n",
    "                if parsing_result==None or len(parsing_result)!=len(entlabels):\n",
    "                    #parsing出现错误\n",
    "                    parsing_error_count+=1\n",
    "                    continue\n",
    "                    \n",
    "                for i in range(len(parsing_result)):\n",
    "                    word,pos_tag,head_id,deprel=parsing_result[i]\n",
    "                    ent=entlabels[i]\n",
    "                    lemma='_'\n",
    "                    feats='_'\n",
    "                    conllx_example=[str(i+1),word,lemma,pos_tag,pos_tag,feats,str(head_id),deprel,'_','_',ent]\n",
    "                    f.write('\\t'.join(conllx_example)+'\\n')\n",
    "                    \n",
    "                f.write('\\n')\n",
    "            print(\"parsing error count : \",parsing_error_count,len(sentences_and_entlabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f45c8c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.word.bmes', 'test.word.bmes', 'dev.word.bmes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 14041/14041 [00:53<00:00, 260.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing error count :  4026 14041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 3453/3453 [00:13<00:00, 256.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing error count :  979 3453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 3250/3250 [00:13<00:00, 249.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing error count :  1030 3250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "process_data(path_folder=path_folder,write_path='/home/xhsun/Desktop/gitRepositories/DP-Relatedwork-BrieflySummarize/data/CoNLL03/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80853096",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(\"Brussels 1996-08-22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b81e1925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brussels Brussels ROOT\n",
      "1996 Brussels nummod\n",
      "- Brussels punct\n",
      "08 22 nummod\n",
      "- 22 punct\n",
      "22 Brussels appos\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token,token.head,token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e916dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
