{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a55653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,json,os\n",
    "import torch.nn as nn\n",
    "from transformers import AutoConfig,AutoModel\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97f35109",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERNetwork(nn.Module):\n",
    "    \"\"\"A Generic Network for NERDA models.\n",
    "    The network has an analogous architecture to the models in\n",
    "    [Hvingelby et al. 2020](http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.565.pdf).\n",
    "    Can be replaced with a custom user-defined network with \n",
    "    the restriction, that it must take the same arguments.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name_or_path: str, n_tags: int, dropout: float = 0.1) -> None:\n",
    "        \"\"\"Initialize a NERDA Network\n",
    "        Args:\n",
    "            bert_model (nn.Module): huggingface `torch` transformers.\n",
    "            device (str): Computational device.\n",
    "            n_tags (int): Number of unique entity tags (incl. outside tag)\n",
    "            dropout (float, optional): Dropout probability. Defaults to 0.1.\n",
    "        \"\"\"\n",
    "        super(NERNetwork, self).__init__()\n",
    "        \n",
    "        # extract AutoConfig, from which relevant parameters can be extracted.\n",
    "        bert_model_config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "        self.bert_model = AutoModel.from_pretrained(model_name_or_path)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.tags = nn.Linear(bert_model_config.hidden_size, n_tags)#BERT+Linear\n",
    "\n",
    "    def forward(self, \n",
    "                input_ids: torch.Tensor, \n",
    "                attention_mask: torch.Tensor, \n",
    "                token_type_ids: torch.Tensor,\n",
    "                ) -> torch.Tensor:\n",
    "        \"\"\"Model Forward Iteration\n",
    "        Args:\n",
    "            input_ids (torch.Tensor): Input IDs.\n",
    "            attention_mask (torch.Tensor): Attention attention_mask.\n",
    "            token_type_ids (torch.Tensor): Token Type IDs.\n",
    "        Returns:\n",
    "            torch.Tensor: predicted values.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: can be improved with ** and move everything to device in a\n",
    "        # single step.\n",
    "        bert_model_inputs = {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'token_type_ids': token_type_ids\n",
    "            }\n",
    "        \n",
    "        # match args with bert_model\n",
    "        # bert_model_inputs = match_kwargs(self.bert_model.forward, **bert_model_inputs)\n",
    "           \n",
    "        outputs = self.bert_model(**bert_model_inputs)\n",
    "        # apply drop-out\n",
    "        last_hidden_state=outputs.last_hidden_state\n",
    "        last_hidden_state = self.dropout(last_hidden_state)\n",
    "\n",
    "        # last_hidden_state for all labels/tags\n",
    "        last_hidden_state = self.tags(last_hidden_state)\n",
    "\n",
    "        return last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff60a971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir='/home/xhsun/Desktop/NER_Parsing/train_models/baseline_models'\n",
    "tag_complete=json.load(open(os.path.join(save_dir,'label.json'))).split(' ')\n",
    "tag_encoder=sklearn.preprocessing.LabelEncoder()\n",
    "tag_encoder.fit(tag_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aad7ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG',\n",
       "       'I-PER', 'O'], dtype='<U6')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a248c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e20477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380f2731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43232f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "913065b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device automatically set to: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30eb19d6fc3f4cffa0b57b4371ae1dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc8df5da89742098b65bbd2bfcd7f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/641M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0d822e7a4b498186e7d03b2803867b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7d40eea5c24712a14040c8cd69f27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/851k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e9c17ac42e4db09afa5058bf4c77bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.64M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from NERDA.datasets import get_conll_data\n",
    "model = NERDA(dataset_training = get_conll_data('train'),\n",
    "              dataset_validation = get_conll_data('valid'),\n",
    "              transformer = 'bert-base-multilingual-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f71e65fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍           | 1003/1080 [01:03<00:04, 15.84it/s]/home/xhsun/miniconda3/lib/python3.9/site-packages/NERDA/preprocessing.py:80: UserWarning: Sentence #13066 length 157 exceeds max_len 128 and has been truncated\n",
      "  warnings.warn(msg)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1080/1080 [01:08<00:00, 15.71it/s]\n",
      " 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 267/407 [00:03<00:01, 85.96it/s]/home/xhsun/miniconda3/lib/python3.9/site-packages/NERDA/preprocessing.py:80: UserWarning: Sentence #2184 length 137 exceeds max_len 128 and has been truncated\n",
      "  warnings.warn(msg)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 407/407 [00:04<00:00, 84.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.2562131281109975 Valid Loss = 0.10333481829908633\n",
      "\n",
      " Epoch 2 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍           | 1003/1080 [01:03<00:04, 15.93it/s]/home/xhsun/miniconda3/lib/python3.9/site-packages/NERDA/preprocessing.py:80: UserWarning: Sentence #13066 length 157 exceeds max_len 128 and has been truncated\n",
      "  warnings.warn(msg)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1080/1080 [01:08<00:00, 15.72it/s]\n",
      " 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 267/407 [00:03<00:01, 84.98it/s]/home/xhsun/miniconda3/lib/python3.9/site-packages/NERDA/preprocessing.py:80: UserWarning: Sentence #2184 length 137 exceeds max_len 128 and has been truncated\n",
      "  warnings.warn(msg)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 407/407 [00:04<00:00, 83.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.07882672009883983 Valid Loss = 0.07510552785006931\n",
      "\n",
      " Epoch 3 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎           | 1002/1080 [01:04<00:04, 15.69it/s]/home/xhsun/miniconda3/lib/python3.9/site-packages/NERDA/preprocessing.py:80: UserWarning: Sentence #13066 length 157 exceeds max_len 128 and has been truncated\n",
      "  warnings.warn(msg)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1080/1080 [01:09<00:00, 15.54it/s]\n",
      " 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 267/407 [00:03<00:01, 85.21it/s]/home/xhsun/miniconda3/lib/python3.9/site-packages/NERDA/preprocessing.py:80: UserWarning: Sentence #2184 length 137 exceeds max_len 128 and has been truncated\n",
      "  warnings.warn(msg)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 407/407 [00:04<00:00, 84.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.03754968284343636 Valid Loss = 0.0650229681199857\n",
      "\n",
      " Epoch 4 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎           | 1002/1080 [01:04<00:04, 15.78it/s]/home/xhsun/miniconda3/lib/python3.9/site-packages/NERDA/preprocessing.py:80: UserWarning: Sentence #13066 length 157 exceeds max_len 128 and has been truncated\n",
      "  warnings.warn(msg)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1080/1080 [01:09<00:00, 15.48it/s]\n",
      " 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 267/407 [00:03<00:01, 85.94it/s]/home/xhsun/miniconda3/lib/python3.9/site-packages/NERDA/preprocessing.py:80: UserWarning: Sentence #2184 length 137 exceeds max_len 128 and has been truncated\n",
      "  warnings.warn(msg)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 407/407 [00:04<00:00, 84.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.017491656300518552 Valid Loss = 0.06647421490569146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Model trained successfully'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92ba2852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhsun/miniconda3/lib/python3.9/site-packages/NERDA/preprocessing.py:80: UserWarning: Sentence #202 length 139 exceeds max_len 128 and has been truncated\n",
      "  warnings.warn(msg)\n",
      "/home/xhsun/miniconda3/lib/python3.9/site-packages/NERDA/performance.py:39: UserWarning: length of observed values exceeded lengths of predicted values in 1 cases and were truncated. _Consider_ increasing max_len parameter for your model.\n",
      "  warnings.warn(f'length of observed values exceeded lengths of predicted values in {n_exceeds} cases and were truncated. _Consider_ increasing max_len parameter for your model.')\n",
      "/home/xhsun/miniconda3/lib/python3.9/site-packages/NERDA/performance.py:39: UserWarning: length of observed values exceeded lengths of predicted values in 1 cases and were truncated. _Consider_ increasing max_len parameter for your model.\n",
      "  warnings.warn(f'length of observed values exceeded lengths of predicted values in {n_exceeds} cases and were truncated. _Consider_ increasing max_len parameter for your model.')\n",
      "/home/xhsun/miniconda3/lib/python3.9/site-packages/NERDA/performance.py:39: UserWarning: length of observed values exceeded lengths of predicted values in 1 cases and were truncated. _Consider_ increasing max_len parameter for your model.\n",
      "  warnings.warn(f'length of observed values exceeded lengths of predicted values in {n_exceeds} cases and were truncated. _Consider_ increasing max_len parameter for your model.')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [46014, 46003]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14653/4227849108.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_conll_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_accuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/NERDA/models.py\u001b[0m in \u001b[0;36mevaluate_performance\u001b[0;34m(self, dataset, return_accuracy, **kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# compute and return accuracy if desired\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_accuracy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m             accuracy = accuracy_score(y_pred = flatten(tags_predicted), \n\u001b[0m\u001b[1;32m    406\u001b[0m                                       y_true = flatten(dataset.get('tags')))\n\u001b[1;32m    407\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [46014, 46003]"
     ]
    }
   ],
   "source": [
    "test = get_conll_data('test')\n",
    "model.evaluate_performance(test,return_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae9151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f505ead6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8612500000000001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.96+0.98+0.87+0.86+0.92+0.82+0.82+0.66)/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f831f0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
