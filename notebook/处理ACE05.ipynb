{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34eaefec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,json\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79614abc",
   "metadata": {},
   "source": [
    "# ACE05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e200156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mrc-ner.dev', 'mrc-ner.test', 'mrc-ner.train']\n"
     ]
    }
   ],
   "source": [
    "path_folder='/home/xhsun/NLP/NER/NerData/ace2005'\n",
    "files_path=os.listdir(path_folder)\n",
    "print(files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c1a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606f0348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1103234",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/xhsun/NLP/NER/NerData/ace2005/mrc-ner.train\") as f:\n",
    "    data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc2e27ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': \"BEGALA Well , we ' ll debate that later on in the show .\",\n",
       " 'end_position': [],\n",
       " 'entity_label': 'GPE',\n",
       " 'impossible': True,\n",
       " 'qas_id': '0.1',\n",
       " 'query': 'geographical political entities are geographical regions defined by political and or social groups such as countries, nations, regions, cities, states, government and its people.',\n",
       " 'span_position': [],\n",
       " 'start_position': []}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78b74e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_examples(examples):\n",
    "    '''\n",
    "    传进来的examples都是一个question对应的example\n",
    "    '''\n",
    "    sentence=examples[0]['context']\n",
    "    sentence_list=sentence.split()\n",
    "    entlabel_list=['O']*len(sentence_list)\n",
    "    for example in examples:\n",
    "        assert example['context']==sentence\n",
    "        span_positions=example['span_position']\n",
    "        impossible=str(example['impossible']).lower()\n",
    "        if impossible==\"true\":\n",
    "            assert span_positions==[]\n",
    "            continue\n",
    "        assert span_positions!=[]\n",
    "        entity_label=example['entity_label']\n",
    "\n",
    "        for start_end in span_positions:\n",
    "            start,end=list(map(int,start_end.split(';')))\n",
    "            #采用BMES标记\n",
    "            if start==end:\n",
    "                if entlabel_list[start]=='O':\n",
    "                    entlabel_list[start]=('S-'+entity_label)\n",
    "                else:\n",
    "                    #嵌套实体\n",
    "                    if entity_label not in entlabel_list[start]:\n",
    "                        #如果之前已经标记为M-ORG，那么就不再标记为S-ORG了，但是\n",
    "                        #如果之前标记的是M-PER，那么仍然会标记为S-ORG\n",
    "                        entlabel_list[start]+=('+S-'+entity_label)\n",
    "            else:\n",
    "                for pos in range(start,end+1):\n",
    "                    if pos==start:\n",
    "                        if entlabel_list[pos]=='O':\n",
    "                            entlabel_list[pos]='B-'+entity_label\n",
    "                        else:\n",
    "                            #嵌套实体\n",
    "                            if entity_label not in entlabel_list[start]:\n",
    "                                entlabel_list[pos]+=('+B-'+entity_label)\n",
    "                            else:\n",
    "                                #如果发现实体已经被打上同样的tag，那么就不再标记\n",
    "                                break\n",
    "                    elif pos<end:\n",
    "                        if entlabel_list[pos]=='O':\n",
    "                            entlabel_list[pos]='M-'+entity_label\n",
    "                        else:\n",
    "                            #嵌套实体\n",
    "                            entlabel_list[pos]+=('+M-'+entity_label)                        \n",
    "                    else:\n",
    "                        assert pos==end\n",
    "                        if entlabel_list[pos]=='O':\n",
    "                            entlabel_list[pos]='E-'+entity_label\n",
    "                        else:\n",
    "                            #嵌套实体\n",
    "                            entlabel_list[pos]+=('+E-'+entity_label)\n",
    "        \n",
    "    return sentence_list,entlabel_list\n",
    "\n",
    "def process_ace_data(path_folder,write_path):\n",
    "    i=0\n",
    "    files_path=os.listdir(path_folder)\n",
    "    print(files_path)\n",
    "    for file_name in files_path:\n",
    "        with open(os.path.join(path_folder,file_name)) as f:\n",
    "            data=json.load(f)\n",
    "        sentence_count=0\n",
    "        mode=file_name.split('.')[-1]\n",
    "        f_write=open(os.path.join(write_path,mode),'w')\n",
    "        while i<len(data)-2:\n",
    "            example=data[i]\n",
    "            examples_for_i=[example]\n",
    "            qas_id=int(example['qas_id'].split('.')[0])\n",
    "            j=i+1\n",
    "            while j<len(data):\n",
    "                if int(data[j]['qas_id'].split('.')[0])==qas_id:\n",
    "                    examples_for_i.append(data[j])\n",
    "                else:\n",
    "                    break\n",
    "                j+=1\n",
    "            i=j\n",
    "            sentence_list_i,entlabel_list_i=process_examples(examples=examples_for_i)\n",
    "            assert len(sentence_list_i)==len(entlabel_list_i)\n",
    "            for token,entlabel in zip(sentence_list_i,entlabel_list_i):\n",
    "                f_write.write(token+'\\t'+entlabel+'\\n')\n",
    "            f_write.write('\\n')\n",
    "            sentence_count+=1\n",
    "        print(file_name,sentence_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "349a3f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mrc-ner.dev', 'mrc-ner.test', 'mrc-ner.train']\n",
      "mrc-ner.dev 971\n",
      "mrc-ner.test 89\n",
      "mrc-ner.train 6239\n"
     ]
    }
   ],
   "source": [
    "process_ace_data(path_folder=path_folder,\n",
    "                 write_path='/home/xhsun/Desktop/gitRepositories/DP-Relatedwork-BrieflySummarize/data/ACE05/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5438193",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"We ' ll have a couple of experts come out , so I ' ll withhold my comments until then .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c7b0f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'couple', 'of', 'experts']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.split()[4:7+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d02b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.split()[12:12+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e97794a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.split()[16:16+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "363dd95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'False'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71746d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[89, 34]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_end='89;34'\n",
    "list(map(int,start_end.split(';')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ca782b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
